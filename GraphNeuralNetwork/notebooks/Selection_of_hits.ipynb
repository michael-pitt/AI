{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trackML challenge \n",
    "\n",
    "This notebook used to generate inputs and train the model, both model and the input reprocessing are defined in `sample_code_submission/`\n",
    "\n",
    "#### optimization:\n",
    "to optimize the code try `!cython preprocess.pyx -a`\n",
    "\n",
    "In this notebook we will examine when we can merge close hits, and we will validate the evaluation of the cython code for data preparation:\n",
    "\n",
    "\n",
    "**[Hit merging](#merging)** - evaluation of criteria for close hits that share the same track\n",
    "\n",
    "**[Validation](#validation)** - validation of the cython code\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trackml.dataset import load_dataset\n",
    "PATH_TO_DATA = \"/home/data/train_sample_single\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset(PATH_TO_DATA, parts=['hits', 'cells', 'truth', 'particles'])\n",
    "event_id, hits, cells, truth, particles = next(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['hit_id', 'particle_id', 'tx', 'ty', 'tz', 'tpx', 'tpy', 'tpz',\n",
       "       'weight'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_keys = truth.keys()\n",
    "new_truth = truth.merge(hits[['hit_id','volume_id']])\n",
    "mask = ((new_truth['volume_id']==8) | (new_truth['volume_id']==13) | (new_truth['volume_id']==18))\n",
    "new_truth = new_truth.loc[mask][old_keys]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='merging'></a>\n",
    "\n",
    "## Hit merging:\n",
    "\n",
    "\n",
    "Check for the criteria to merge hits (some of the hits in the layer 1 will originating from the same particle, therefore we will assign same label (`track_id`) to those hits\n",
    "\n",
    "Lets obtain the distribtion to decide on the cut criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLayer(r, z, volume_id, layer_id):   \n",
    "    if volume_id==8 and layer_id==2:\n",
    "        return 1\n",
    "    elif volume_id==9:\n",
    "        return 2\n",
    "    elif volume_id==7:\n",
    "        return 2\n",
    "    else: return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits['r'] = np.sqrt(hits['x']**2 + hits['y']**2)\n",
    "hits['phi'] = np.arctan2(hits['y'],hits['x'])\n",
    "hits['theta'] = np.arctan2(hits['r'],hits['z'])\n",
    "hits['eta'] = -np.log(np.tan(0.5*hits['theta']))\n",
    "hits['evtid'] = event_id\n",
    "hits['layer'] = hits.apply(lambda x: getLayer(x['r'],x['z'],x['volume_id'],x['layer_id']), axis=1)\n",
    "keys = ['hit_id','z','phi','r','layer']\n",
    "hits = (hits[keys].merge(truth[['hit_id','particle_id']], on='hit_id'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sudy the hits from the first layer only (separate barrel with end-caps):\n",
    "\n",
    "Let's order the hits in increasing order in $\\phi$, and look on a neighbour hits.\n",
    "By construction, these two hits are close in $\\phi$, the question which criteria one should apply to verify that these two hits are comming form the same track:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_hits = hits.loc[hits['layer']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_sorted_hits = filter_hits.sort_values(by=['phi'])\n",
    "n = filtered_sorted_hits.shape[0]\n",
    "dphi = []\n",
    "dz = []\n",
    "dr = []\n",
    "is_true = []\n",
    "for i in range(n-1):\n",
    "    is_true.append( filtered_sorted_hits.particle_id.values[i] == filtered_sorted_hits.particle_id.values[i+1]  )\n",
    "    dphi.append( filtered_sorted_hits.phi.values[i+1] - filtered_sorted_hits.phi.values[i]  ) \n",
    "    dz.append( filtered_sorted_hits.z.values[i+1] - filtered_sorted_hits.z.values[i]  ) \n",
    "    dr.append( filtered_sorted_hits.r.values[i+1] - filtered_sorted_hits.r.values[i]  ) \n",
    "dphi = np.array(dphi)\n",
    "dz = np.array(dz)\n",
    "dr = np.array(dr)\n",
    "is_true = np.array(is_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 5))\n",
    "ax = fig.add_subplot(1, 3, 1)\n",
    "ax.hist(dphi[(is_true==False) ],100,(-0.001,0.006),label='false')\n",
    "ax.hist(dphi[(is_true==True) ],100,(-0.001,0.006),label='true',log=True)\n",
    "ax.set_xlabel(r'$\\Delta\\phi [rad]$',fontsize=20)\n",
    "\n",
    "ax = fig.add_subplot(1, 3, 2)\n",
    "ax.hist(dr[(is_true==False) & (dphi<0.002) ],100,(-1,1),label='false')\n",
    "ax.hist(dr[(is_true==True) & (dphi<0.002) ],100,(-1,1),label='true', log=True)\n",
    "ax.set_xlabel(r'$\\Delta R [mm]$',fontsize=20)\n",
    "\n",
    "ax = fig.add_subplot(1, 3, 3)\n",
    "ax.hist(dz[(is_true==False) & (np.fabs(dr)>0.025) & (dphi<0.002)],100,(-20,20),label='false')\n",
    "ax.hist(dz[(is_true==True) & (np.fabs(dr)>0.025) & (dphi<0.002)],100,(-20,20),label='true',alpha=0.4)\n",
    "ax.set_xlabel(r'$\\Delta z [mm]$',fontsize=20)\n",
    "\n",
    "plt.legend()\n",
    "plt.savefig('Merge_hits_Barrel.pdf')\n",
    "plt.show()   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_hits = hits.loc[hits['layer']==2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_sorted_hits = filter_hits.sort_values(by=['phi'])\n",
    "n = filtered_sorted_hits.shape[0]\n",
    "dphi = []\n",
    "dz = []\n",
    "dr = []\n",
    "is_true = []\n",
    "for i in range(n-1):\n",
    "    is_true.append( filtered_sorted_hits.particle_id.values[i] == filtered_sorted_hits.particle_id.values[i+1]  )\n",
    "    dphi.append( filtered_sorted_hits.phi.values[i+1] - filtered_sorted_hits.phi.values[i]  ) \n",
    "    dz.append( filtered_sorted_hits.z.values[i+1] - filtered_sorted_hits.z.values[i]  ) \n",
    "    dr.append( filtered_sorted_hits.r.values[i+1] - filtered_sorted_hits.r.values[i]  ) \n",
    "dphi = np.array(dphi)\n",
    "dz = np.array(dz)\n",
    "dr = np.array(dr)\n",
    "is_true = np.array(is_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 5))\n",
    "ax = fig.add_subplot(1, 3, 1)\n",
    "ax.hist(dphi[(is_true==False) ],100,(-0.001,0.006),label='false')\n",
    "ax.hist(dphi[(is_true==True) ],100,(-0.001,0.006),label='true',log=True)\n",
    "ax.set_xlabel(r'$\\Delta\\phi [rad]$',fontsize=20)\n",
    "\n",
    "ax = fig.add_subplot(1, 3, 2)\n",
    "ax.hist(dz[(is_true==False) & (dphi<0.001)],100,(-1,1),label='false')\n",
    "ax.hist(dz[(is_true==True) & (dphi<0.001)],100,(-1,1),label='true', log=True)\n",
    "ax.set_xlabel(r'$\\Delta z [mm]$',fontsize=20)\n",
    "\n",
    "ax = fig.add_subplot(1, 3, 3)\n",
    "ax.hist(dr[(is_true==False) & (dphi<0.001) & (np.fabs(dz)>0.25) ],100,(-5,5),label='false')\n",
    "ax.hist(dr[(is_true==True) & (dphi<0.001) & (np.fabs(dz)>0.25) ],100,(-5,5),label='true',alpha=0.6, log=True)\n",
    "ax.set_xlabel(r'$\\Delta R [mm]$',fontsize=20)\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.savefig('Merge_hits_EC.pdf')\n",
    "plt.show()   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='validation'></a>\n",
    "\n",
    "## Validation of segment selection:\n",
    "\n",
    "consider a single (eta,phi) window, extract tracks using the code, and usigg the dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi_bins = np.linspace(0,0.5,2)\n",
    "eta_bins = np.linspace(0,0.1,2)\n",
    "data = load_dataset(PATH_TO_DATA, parts=['hits', 'cells', 'truth', 'particles'])\n",
    "event_id, hits, cells, truth, particles = next(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add layer index to the hits dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLayer(volume_id, layer_id):   \n",
    "    if volume_id==8:\n",
    "        return layer_id/2\n",
    "    elif volume_id==13:\n",
    "        return layer_id/2 + 4\n",
    "    elif volume_id==17:\n",
    "        return layer_id/2 + 8\n",
    "    elif volume_id==7:\n",
    "        return 8 - layer_id/2\n",
    "    elif volume_id==9:\n",
    "        return layer_id/2\n",
    "    elif volume_id==12:\n",
    "        return 7 - layer_id/2\n",
    "    elif volume_id==14:\n",
    "        return layer_id/2\n",
    "    elif volume_id==16:\n",
    "        return 7 - layer_id/2\n",
    "    elif volume_id==18:\n",
    "        return layer_id/2\n",
    "    else: return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits['layer'] = hits.apply(lambda x: getLayer(x['volume_id'],x['layer_id']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the truth info from the `cells` and `truth` dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_hits = hits.merge(truth[['hit_id','particle_id']], on='hit_id')[['hit_id','x','y','z','particle_id','layer']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_hits['evtid'] = event_id\n",
    "merged_hits['r'] = np.sqrt(merged_hits['x']**2 + merged_hits['y']**2)\n",
    "theta = np.arctan2(merged_hits['r'],merged_hits['z'].values)\n",
    "merged_hits['phi'] = np.arctan2(merged_hits['y'],merged_hits['x'])\n",
    "merged_hits['eta'] = -np.log(np.tan(0.5*theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remanining 119 hits\n"
     ]
    }
   ],
   "source": [
    "mask = (merged_hits['eta']>eta_bins[0]) & (merged_hits['eta']<eta_bins[1]) \\\n",
    "     & (merged_hits['phi']>phi_bins[0]) & (merged_hits['phi']<phi_bins[1])\n",
    "filtered_hits = merged_hits.loc[mask]\n",
    "print('remanining',filtered_hits.shape[0],'hits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hit_id</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>particle_id</th>\n",
       "      <th>layer</th>\n",
       "      <th>evtid</th>\n",
       "      <th>r</th>\n",
       "      <th>phi</th>\n",
       "      <th>eta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18092</th>\n",
       "      <td>18093</td>\n",
       "      <td>29.371799</td>\n",
       "      <td>12.75130</td>\n",
       "      <td>0.903263</td>\n",
       "      <td>337777806073135104</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21100</td>\n",
       "      <td>32.020279</td>\n",
       "      <td>0.409582</td>\n",
       "      <td>0.028205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18096</th>\n",
       "      <td>18097</td>\n",
       "      <td>30.642099</td>\n",
       "      <td>9.11798</td>\n",
       "      <td>0.409374</td>\n",
       "      <td>166643425414742016</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21100</td>\n",
       "      <td>31.969921</td>\n",
       "      <td>0.289220</td>\n",
       "      <td>0.012805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19607</th>\n",
       "      <td>19608</td>\n",
       "      <td>28.916300</td>\n",
       "      <td>12.55390</td>\n",
       "      <td>0.673269</td>\n",
       "      <td>337777806073135104</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21100</td>\n",
       "      <td>31.523846</td>\n",
       "      <td>0.409592</td>\n",
       "      <td>0.021356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19618</th>\n",
       "      <td>19619</td>\n",
       "      <td>30.168600</td>\n",
       "      <td>8.97229</td>\n",
       "      <td>0.445777</td>\n",
       "      <td>166643425414742016</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21100</td>\n",
       "      <td>31.474537</td>\n",
       "      <td>0.289074</td>\n",
       "      <td>0.014163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       hit_id          x         y         z         particle_id  layer  \\\n",
       "18092   18093  29.371799  12.75130  0.903263  337777806073135104    1.0   \n",
       "18096   18097  30.642099   9.11798  0.409374  166643425414742016    1.0   \n",
       "19607   19608  28.916300  12.55390  0.673269  337777806073135104    1.0   \n",
       "19618   19619  30.168600   8.97229  0.445777  166643425414742016    1.0   \n",
       "\n",
       "       evtid          r       phi       eta  \n",
       "18092  21100  32.020279  0.409582  0.028205  \n",
       "18096  21100  31.969921  0.289220  0.012805  \n",
       "19607  21100  31.523846  0.409592  0.021356  \n",
       "19618  21100  31.474537  0.289074  0.014163  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_hits.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next lines will calculate the sigments using pandas dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "z0_max = 150\n",
    "pt_min =  180\n",
    "rho_min = pt_min/0.6\n",
    "\n",
    "\n",
    "def calc_dphi(hit_pairs):\n",
    "    dphi = hit_pairs.phi_1 - hit_pairs.phi_2\n",
    "    dphi = np.arccos(np.cos(dphi))\n",
    "    return dphi\n",
    "\n",
    "def calc_dr(hit_pairs):\n",
    "    dx = hit_pairs.x_2 - hit_pairs.x_1\n",
    "    dy = hit_pairs.y_2 - hit_pairs.y_1\n",
    "    return np.sqrt(dx**2 + dy**2)   \n",
    "\n",
    "def select_segments(hits1, hits2, rho_min, z0_max):\n",
    "    # Start with all possible pairs of hits\n",
    "    keys = ['evtid', 'r', 'x', 'y', 'phi', 'z']\n",
    "    hit_pairs = hits1[keys].reset_index().merge(\n",
    "        hits2[keys].reset_index(), on='evtid', suffixes=('_1', '_2'))\n",
    "    \n",
    "    # Compute circle radius of two points that cross the origin:\n",
    "    dphi = calc_dphi(hit_pairs)\n",
    "    dr = calc_dr(hit_pairs)\n",
    "    rho = 0.5 * dr / dphi\n",
    "    \n",
    "    # compute line through the points in z direction:\n",
    "    dz = hit_pairs.z_2 - hit_pairs.z_1\n",
    "    tanL = -dz / dr\n",
    "    z0_1 = hit_pairs.z_1 + hit_pairs.r_1 * tanL\n",
    "    z0_2 = hit_pairs.z_2 + hit_pairs.r_2 * tanL\n",
    "    #    0.5(hit_pairs.z_2 + hit_pairs.z_1) + 0.5*(hit_pairs.r_2 + hit_pairs.r_1)*tanL\n",
    "    \n",
    "    # Filter segments according to criteria\n",
    "    good_seg_mask = (rho.abs() > rho_min) & (z0_1.abs() < z0_max)  & (z0_2.abs() < z0_max)\n",
    "    return hit_pairs[['index_1', 'index_2']][good_seg_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_det_layers = 10\n",
    "hits_for_graphs = filtered_hits.loc[filtered_hits['layer']<n_det_layers+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate for 1 - 2, evaluate for 2 - 3, evaluate for 3 - 4, evaluate for 4 - 5, evaluate for 5 - 6, evaluate for 6 - 7, evaluate for 7 - 8, evaluate for 8 - 9, evaluate for 9 - 10, Done\n"
     ]
    }
   ],
   "source": [
    "l = np.arange(n_det_layers)\n",
    "layer_pairs = np.stack([l[:-1]+1, l[1:]+1], axis=1)\n",
    "layer_groups = hits_for_graphs.groupby('layer')\n",
    "segments = []\n",
    "for (layer1, layer2) in layer_pairs:\n",
    "    print('evaluate for',layer1,'-',layer2,end=\", \",flush=False)\n",
    "    hits1 = layer_groups.get_group(layer1)\n",
    "    hits2 = layer_groups.get_group(layer2)\n",
    "    segments.append(select_segments(hits1, hits2, rho_min, z0_max))\n",
    "segments = pd.concat(segments)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_hits = 119 n_edges = 968\n"
     ]
    }
   ],
   "source": [
    "n_hits = hits_for_graphs.shape[0]\n",
    "n_edges = segments.shape[0]\n",
    "print('n_hits =',n_hits,'n_edges =',n_edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the graph matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['x', 'y', 'z','phi','eta']\n",
    "X = (hits_for_graphs[feature_names].values).astype(np.float32)\n",
    "hit_id = (hits_for_graphs['hit_id'].values).astype(np.int32)\n",
    "pid = (hits_for_graphs['particle_id'].values).astype(np.int64)\n",
    "y = np.zeros(n_edges, dtype=np.float32)\n",
    "Is = np.zeros((n_edges, 2), dtype=np.int16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a series to map hit label-index onto positional-index and use use `particle_id` to label connected nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_idx = pd.Series(np.arange(n_hits), index=hits_for_graphs.index)\n",
    "seg_start = hit_idx.loc[segments.index_1].values[:,None]\n",
    "seg_end = hit_idx.loc[segments.index_2].values[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y stats: connected -  29  disconnected -  939  total - 968\n"
     ]
    }
   ],
   "source": [
    "pid1 = hits_for_graphs.particle_id.loc[segments.index_1].values\n",
    "pid2 = hits_for_graphs.particle_id.loc[segments.index_2].values\n",
    "Is = np.concatenate([seg_start,seg_end],axis=1)\n",
    "y[:] = (pid1 == pid2)\n",
    "y[pid1 ==0 ] = 0\n",
    "print('Y stats: connected - ',(y==1).sum(),' disconnected - ',(y==0).sum(),' total -',y.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n nodes =  119  n edges =  899\n"
     ]
    }
   ],
   "source": [
    "#using the code:\n",
    "from preprocess import preprocess\n",
    "list_X, list_Is, list_hits_id, list_labels = preprocess(hits.copy(),phi_bins, eta_bins)\n",
    "list_X, list_Is, list_hits_id, list_labels = list_X[0], list_Is[0], list_hits_id[0], list_labels[0]\n",
    "print('n nodes = ',np.concatenate(list_X).shape[0],' n edges = ',np.concatenate(list_Is).shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make comparison between selected connections between the nodes, using both methods:\n",
    "\n",
    "From method #1 we have $n_\\text{edges}\\times 2$ matrix $I_s$ contains the position of node from matrix $X$\n",
    "\n",
    "From method #2 we have $9$ matrices $I_s$ and $10$ matrices $X$ correspond to the nodes form each layer and the links betwen them. The links are given as $pos1, pos2$ where the possition are correspond to the rows of matrices $X[0]$ and $X[1]$\n",
    "\n",
    "let's compare the first 3 nodes connections, for first 3 nodes we have 11 links:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "method #1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features of node 1,2,3 and node N connected to node 1,2,3:\n",
      " node 0 is  29.37 12.75 0.90 0.41 0.03  hit_id 18093 pid 337777806073135104\n",
      " node 1 is  30.64 9.12 0.41 0.29 0.01  hit_id 18097 pid 166643425414742016\n",
      " node 2 is  28.92 12.55 0.67 0.41 0.02  hit_id 19608 pid 337777806073135104\n",
      " node 3 is  30.17 8.97 0.45 0.29 0.01  hit_id 19619 pid 166643425414742016\n",
      " node 4 is  30.56 7.84 2.74 0.25 0.09  hit_id 19636 pid 166638065295556608\n",
      "0 -> [ 10 ] =  66.08 26.39 3.44 0.38 0.05  id 26210 pid 824163061135835136\n",
      "0 -> [ 11 ] =  66.05 26.45 0.93 0.38 0.01  id 26219 pid 94586999607918592\n",
      "0 -> [ 12 ] =  68.03 27.32 2.66 0.38 0.04  id 26229 pid 824163061135835136\n",
      "0 -> [ 13 ] =  65.29 31.07 4.10 0.44 0.06  id 26233 pid 495400425776742400\n",
      "0 -> [ 14 ] =  68.13 27.18 2.08 0.38 0.03  id 26237 pid 94586999607918592\n",
      "1 -> [ 9 ] =  70.78 16.27 1.78 0.23 0.02  id 26209 pid 166638065295556608\n",
      "2 -> [ 10 ] =  66.08 26.39 3.44 0.38 0.05  id 26210 pid 824163061135835136\n",
      "2 -> [ 11 ] =  66.05 26.45 0.93 0.38 0.01  id 26219 pid 94586999607918592\n",
      "2 -> [ 12 ] =  68.03 27.32 2.66 0.38 0.04  id 26229 pid 824163061135835136\n",
      "2 -> [ 13 ] =  65.29 31.07 4.10 0.44 0.06  id 26233 pid 495400425776742400\n",
      "2 -> [ 14 ] =  68.13 27.18 2.08 0.38 0.03  id 26237 pid 94586999607918592\n",
      "3 -> [ 9 ] =  70.78 16.27 1.78 0.23 0.02  id 26209 pid 166638065295556608\n",
      "4 -> [ 8 ] =  69.45 15.09 0.15 0.21 0.00  id 26200 pid 0\n",
      "4 -> [ 9 ] =  70.78 16.27 1.78 0.23 0.02  id 26209 pid 166638065295556608\n"
     ]
    }
   ],
   "source": [
    "print('features of node 1,2,3 and node N connected to node 1,2,3:')\n",
    "print(' node 0 is ', '%2.2f %2.2f %2.2f %2.2f %2.2f'%tuple(X[0]),' hit_id',hit_id[0],'pid',pid[0])\n",
    "print(' node 1 is ', '%2.2f %2.2f %2.2f %2.2f %2.2f'%tuple(X[1]),' hit_id',hit_id[1],'pid',pid[1])\n",
    "print(' node 2 is ', '%2.2f %2.2f %2.2f %2.2f %2.2f'%tuple(X[2]),' hit_id',hit_id[2],'pid',pid[2])\n",
    "print(' node 3 is ', '%2.2f %2.2f %2.2f %2.2f %2.2f'%tuple(X[3]),' hit_id',hit_id[3],'pid',pid[3])\n",
    "print(' node 4 is ', '%2.2f %2.2f %2.2f %2.2f %2.2f'%tuple(X[4]),' hit_id',hit_id[4],'pid',pid[4])\n",
    "\n",
    "for i in Is[:14]:\n",
    "    print(i[0],'-> [',i[1],'] = ','%2.2f %2.2f %2.2f %2.2f %2.2f'%tuple(X[i[1]]),' id',hit_id[i[1]],'pid',pid[i[1]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "medhod #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features of node 1,2,3,4,5 and node N connected to node 1,2,3,4,5:\n",
      " node 0 is  29.37 12.75 0.90 0.41 0.03 id 18093\n",
      " node 1 is  30.64 9.12 0.41 0.29 0.01 id 18097\n",
      " node 2 is  28.92 12.55 0.67 0.41 0.02 id 19608\n",
      " node 3 is  30.17 8.97 0.45 0.29 0.01 id 19619\n",
      " node 4 is  30.56 7.84 2.74 0.25 0.09 id 19636\n"
     ]
    }
   ],
   "source": [
    "#position of the nodes that were selected previously:\n",
    "pos = [5, 3, 6, 2, 1]\n",
    "print('features of node 1,2,3,4,5 and node N connected to node 1,2,3,4,5:')\n",
    "for i in range(5):\n",
    "    print(' node %d is '%i, '%2.2f %2.2f %2.2f %2.2f %2.2f'%tuple(list_X[0][pos[i]]),'id',list_hits_id[0][pos[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -> [ 3 ] =  68.13 27.18 2.08 0.38 0.03 id 26237\n",
      "0 -> [ 4 ] =  66.08 26.39 3.44 0.38 0.05 id 26210\n",
      "0 -> [ 5 ] =  66.05 26.45 0.93 0.38 0.01 id 26219\n",
      "0 -> [ 6 ] =  68.03 27.32 2.66 0.38 0.04 id 26229\n",
      "0 -> [ 7 ] =  65.29 31.07 4.10 0.44 0.06 id 26233\n",
      "1 -> [ 2 ] =  70.78 16.27 1.78 0.23 0.02 id 26209\n",
      "2 -> [ 3 ] =  68.13 27.18 2.08 0.38 0.03 id 26237\n",
      "2 -> [ 4 ] =  66.08 26.39 3.44 0.38 0.05 id 26210\n",
      "2 -> [ 5 ] =  66.05 26.45 0.93 0.38 0.01 id 26219\n",
      "2 -> [ 6 ] =  68.03 27.32 2.66 0.38 0.04 id 26229\n",
      "2 -> [ 7 ] =  65.29 31.07 4.10 0.44 0.06 id 26233\n",
      "3 -> [ 2 ] =  70.78 16.27 1.78 0.23 0.02 id 26209\n",
      "4 -> [ 1 ] =  69.45 15.09 0.15 0.21 0.00 id 26200\n",
      "4 -> [ 2 ] =  70.78 16.27 1.78 0.23 0.02 id 26209\n"
     ]
    }
   ],
   "source": [
    "for j in range(5):\n",
    "    for i in list_Is[0].loc[list_Is[0].index_1==pos[j]].index_2.values:\n",
    "        print(j,'-> [',i,'] = ','%2.2f %2.2f %2.2f %2.2f %2.2f'%tuple(list_X[1][i]),'id',list_hits_id[1][i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check label propogation code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GraphBuilder.model_loader import model_loader\n",
    "from GraphBuilder.model.model import GNNmodel as myModel\n",
    "from preprocess import weights_to_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_model = model_loader()\n",
    "graph_model.set_model(myModel())\n",
    "graph_model.load_weights('path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(119,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = graph_model.fit_predict(list_X, list_Is)\n",
    "labels = weights_to_labels(list_X, list_Is, weights, list_labels)\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit_id 18093 label 2\n",
      "connected to\n",
      "0 -> [ 3 ] = id 26237 labeled with [2]\n",
      "0 -> [ 4 ] = id 26210 labeled with [2]\n",
      "0 -> [ 5 ] = id 26219 labeled with [2]\n",
      "0 -> [ 6 ] = id 26229 labeled with [2]\n",
      "0 -> [ 7 ] = id 26233 labeled with [2]\n",
      "hit_id 18097 label 2\n",
      "connected to\n",
      "1 -> [ 2 ] = id 26209 labeled with [2]\n",
      "hit_id 19608 label 2\n",
      "connected to\n",
      "2 -> [ 3 ] = id 26237 labeled with [2]\n",
      "2 -> [ 4 ] = id 26210 labeled with [2]\n",
      "2 -> [ 5 ] = id 26219 labeled with [2]\n",
      "2 -> [ 6 ] = id 26229 labeled with [2]\n",
      "2 -> [ 7 ] = id 26233 labeled with [2]\n",
      "hit_id 19619 label 1\n",
      "connected to\n",
      "3 -> [ 2 ] = id 26209 labeled with [2]\n",
      "hit_id 19636 label 1\n",
      "connected to\n",
      "4 -> [ 1 ] = id 26200 labeled with [1]\n",
      "4 -> [ 2 ] = id 26209 labeled with [2]\n"
     ]
    }
   ],
   "source": [
    "all_hit_id = np.concatenate(list_hits_id)\n",
    "for j in range(5):\n",
    "    print('hit_id',all_hit_id[pos[j]],'label',labels[pos[j]])\n",
    "    print('connected to')\n",
    "    for i in list_Is[0].loc[list_Is[0].index_1==pos[j]].index_2.values:\n",
    "        print(j,'-> [',i,'] = id',list_hits_id[1][i],'labeled with',labels[all_hit_id==list_hits_id[1][i]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
