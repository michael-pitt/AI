{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch import nn, optim\n",
    "import time, sys\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trackML challenge \n",
    "\n",
    "This notebook used to evaluate the model\n",
    "\n",
    "The inputs are loaded from `/scratch/pitt/trackML/train_graphs` folder, this can be changed\n",
    "\n",
    "Thge model is loaded from `/mnt/lustre/agrp/pitt/ML/trackML/sample_code_submission/GraphBuilder/data/`\n",
    "\n",
    "If running on GPU, run the following cell:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "print('Availability of CUDA:',use_cuda)\n",
    "device = torch.device(\"cuda:1\" if use_cuda else \"cpu\")\n",
    "torch.cuda.set_device(1)\n",
    "idevice = torch.cuda.current_device()\n",
    "print('Will work on device number',idevice,', named: ',torch.cuda.get_device_name(idevice))\n",
    "torch.backends.cudnn.benchmark = True\n",
    "print('device = ',device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model from `GraphBuilder` folder, the model consist of two NN:\n",
    "- First FC NN used to identify bad edges, the efficiency of good edges for thredhold of 0.2 is >98%\n",
    "- Then GNN is applied on the full event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/scratch/pitt/trackML/WeizmannAI\")\n",
    "from model.data_loader import trackDataLoader, collate_fn\n",
    "from model.model import GNNmodel, PreTrainModel\n",
    "from trainer import *\n",
    "from utils import AnalyzeThreshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read files, in total we have 200 files, first 40 file for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "train_files = glob('/scratch/pitt/trackML/graph_full_6var_250MeV_150mmz0_1eta/*')\n",
    "test_files = train_files[:40]\n",
    "test_dataset = trackDataLoader(test_files, 1) #test_file train_files\n",
    "test_loader = DataLoader(test_dataset, batch_size = len(test_files), collate_fn=collate_fn)\n",
    "print('Load',len(test_files),'files')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN models\n",
    "\n",
    "Load two models to clasify edges:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/mnt/lustre/agrp/pitt/ML/trackML/sample_code_submission/GraphBuilder/data/'\n",
    "\n",
    "#first model Deep FC NN for edge estimation \n",
    "model1 = PreTrainModel(hidden_features=32)\n",
    "criterion1 = getattr(nn.functional, 'binary_cross_entropy_with_logits')\n",
    "optimizer1 = optim.Adam(model1.parameters())\n",
    "\n",
    "checkpoint1 = torch.load(PATH+'training_pretrain.pt')\n",
    "model1.load_state_dict(checkpoint1['model_state_dict'])\n",
    "model1.to(device)\n",
    "optimizer1.load_state_dict(checkpoint1['optimizer_state_dict'])\n",
    "cache1 = checkpoint1['cache']\n",
    "\n",
    "#second model: GNN for edge clasification with 8 iteration over the neighbours\n",
    "model2 = GNNmodel(edge_dim = 16, hidden_dim = 32, niter = 8)\n",
    "criterion2 = getattr(nn.functional, 'binary_cross_entropy')\n",
    "optimizer2 = optim.Adam(model2.parameters())\n",
    "\n",
    "checkpoint2 = torch.load(PATH+'training_gnn_filtered2.pt')\n",
    "model2.load_state_dict(checkpoint2['model_state_dict'])\n",
    "model2.to(device)\n",
    "optimizer2.load_state_dict(checkpoint2['optimizer_state_dict'])\n",
    "cache2 = checkpoint2['cache']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check model performance\n",
    "\n",
    "Evaluate the total weight obtained by combining both models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#test_dataset = trackDataLoader(test_files, 1) #test_file train_files\n",
    "#test_loader = DataLoader(test_dataset, batch_size = len(test_file), collate_fn=collate_fn)\n",
    "with torch.no_grad():\n",
    "    inputs, test_target = next(iter(test_loader))\n",
    "    X, Is = inputs\n",
    "    inputs = get_inputs(X, Is, device)\n",
    "    test_pred = torch.sigmoid(model1(inputs))\n",
    "    \n",
    "    #filter first training:\n",
    "    mask_edges = (test_pred > 0.2).nonzero().squeeze().cpu()\n",
    "    Is_filter = Is[mask_edges]\n",
    "    e_masked = test_pred[mask_edges]\n",
    "    test_target_masked = test_target[mask_edges]\n",
    "    inputs = get_inputs(X, Is_filter, device)\n",
    "    inputs.append(e_masked)\n",
    "    \n",
    "    #evaluate second round, and append to the first predictions\n",
    "    test_pred_masked = model2(inputs)\n",
    "    test_pred[mask_edges] = test_pred_masked\n",
    "    \n",
    "    test_target = torch.FloatTensor(test_target)\n",
    "AnalyzeThreshold(test_pred.cpu(), test_target, log=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate prurity and acceptance for few working points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_edge_weight = 0.9\n",
    "print('total stats: %d good and %d fake edges'%(test_target.sum(),(test_target==0).sum()))\n",
    "print('signal eff = %2.2f%% are above threshold'\n",
    "      %(test_target[test_pred>cut_edge_weight].sum()/test_target[test_pred>-1].sum()*100))\n",
    "print('signal purity = above the threshold %2.2f%% are truth edges'\n",
    "      %(test_target[test_pred>cut_edge_weight].sum()/(test_pred>cut_edge_weight).sum()*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### study of misclassified   edges:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
