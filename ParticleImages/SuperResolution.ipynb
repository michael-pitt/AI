{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, urllib.request\n",
    "\n",
    "IS_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "    \n",
    "if IS_COLAB:\n",
    "    from google.colab import files\n",
    "    \n",
    "    #create extra folders\n",
    "    !mkdir -pv data images models\n",
    "\n",
    "    # will install missing packages if running in colab\n",
    "    if 'uproot' not in sys.modules:\n",
    "        print('Installing uproot...')\n",
    "        !pip install uproot\n",
    "\n",
    "    #will download the data if running in colab\n",
    "    urllib.request.urlretrieve('https://cernbox.cern.ch/index.php/s/GRAyoFxBHAlMVpu/download',\n",
    "                               'data/events_6D64x64.root')\n",
    "    urllib.request.urlretrieve('https://cernbox.cern.ch/index.php/s/dZ9r1nvBRTpJMNW/download',\n",
    "                               'data/events_6D64x64_ATLAS_resolution_6D64x64.root')\n",
    "    print('ls data')\n",
    "    !ls data/*\n",
    "\n",
    "    #download additional modules used with the notebook\n",
    "    !wget https://raw.githubusercontent.com/mpitt82/AI/master/ParticleImages/train_helpers.py\n",
    "    !wget https://raw.githubusercontent.com/mpitt82/AI/master/ParticleImages/particleImages_helpers.py\n",
    "\n",
    "    print('Using COLAB: all additional packages are installed and the data is downloaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Super resolution notebook\n",
    "\n",
    "In this notebook, the Super Resolution (SR) will be applied on the detector images. The goal is to reconstruct detector images with higher resolution. In this notebook we will try several approaches for this task.\n",
    "\n",
    "The input data obtained using the [ATLAS-simplified](https://github.com/mpitt82/Geant4-models/tree/master/ATLAS-simplified) Geant4 simulation model. The bare data files are available [here](https://cernbox.cern.ch/index.php/s/oCg3en1GHAvYSTo?path=%2FCalo_RectangularGeo_diPion64x64%2Frun).\n",
    "\n",
    "Using the [Vector2Matrix.cc](https://github.com/mpitt82/Geant4-models/blob/master/ATLAS-simplified/scripts/Vector2Matrix.cc) script $6\\times 64\\times 64$ images are obtaned, then with [Matrix2Matrix6L.cc](https://github.com/mpitt82/Geant4-models/blob/master/ATLAS-simplified/scripts/Matrix2Matrix6L.cc) script Low-resolution images are computed. For democtaric upsaling (used as a first approach) the [Matrix2Matrix6L.cc](https://github.com/mpitt82/Geant4-models/blob/master/ATLAS-simplified/scripts/Matrix6L2Matrix.cc) script can be used. **NOTE** All scripts executed in [CINT](https://root.cern.ch/cint). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standards imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data\n",
    "\n",
    "In this example, we will use two example files from cernbox folder, which have $\\sim$2k events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inputfileHR = 'data/events_6D64x64.root'\n",
    "inputfileLR = 'data/events_6D64x64_ATLAS_resolution_6D64x64.root'\n",
    "\n",
    "f = uproot.open(inputfileHR)\n",
    "treeHR = f['EventTree']\n",
    "\n",
    "f = uproot.open(inputfileLR)\n",
    "treeLR = f['EventTree']\n",
    "\n",
    "print('Total number of events in both files is = '+str(treeHR.numentries)+' (HR) and '+str(treeLR.numentries)+' (LR)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calorimeter images\n",
    "\n",
    "In this section, we will create calorimeter images from the cell hits using LR and HR input files. First we will constract a dataset using SRDataLoader defined in [train_helpers.py](train_helpers.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_helpers import SRDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for now we will use the full data to validate the model\n",
    "train_dataset = SRDataLoader(treeLR, treeHR)\n",
    "test_dataset  = SRDataLoader(treeLR, treeHR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw a random image from the energy matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from particleImages_helpers import DrawEventSR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "DrawEventSR(train_dataset, event_number = 143)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n",
    "In the first implementation, we are using democratic interpulation, from varying detector granularity to a fixed size images of $6\\times 64 \\times 64$. The resulting image we will process through a model to recover the $HR$ image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_number = 0; #change this value to \"1\" if using the second GPU\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print('Availability of CUDA:',use_cuda)\n",
    "print('Availability of CUNN:',torch.backends.cudnn.enabled)\n",
    "print('Total number of GPU devices: ',torch.cuda.device_count())\n",
    "device = torch.device(\"cuda:\"+str(device_number) if torch.cuda.is_available() else \"cpu\")\n",
    "if use_cuda:\n",
    "    torch.cuda.set_device(device_number)\n",
    "    idevice = torch.cuda.current_device()\n",
    "    print('Will work on device number',idevice,', named: ',torch.cuda.get_device_name(idevice))\n",
    "else: print('will run on CPU, using',torch.get_num_threads(),'cores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class double_conv(nn.Module):\n",
    "    '''(conv => BN => ReLU) * 2'''\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(double_conv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 5, padding=2,bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 5, padding=2,bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        return torch.cat([x, out],dim=1)\n",
    "\n",
    "class outconv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(outconv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_ch, out_ch, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "      \n",
    "class SRnet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes):\n",
    "        super(SRnet, self).__init__()\n",
    "        self.conv1 = double_conv(n_channels, n_channels)\n",
    "        self.conv2 = double_conv(2 * n_channels, n_channels)\n",
    "        self.conv3 = double_conv(3 * n_channels, n_channels)\n",
    "        self.outc  = outconv(4 * n_channels, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        initial_energy = x.sum(dim=(2,3)).unsqueeze_(2).unsqueeze_(3)\n",
    "        #print('input.shape',x.shape)\n",
    "        x = self.conv1(x)\n",
    "        #print('x1.shape',x.shape)\n",
    "        x = self.conv2(x)\n",
    "        #print('x2.shape',x.shape)\n",
    "        x = self.conv3(x)\n",
    "        #print('x3.shape',x.shape)\n",
    "        x = self.outc(x)\n",
    "        print('x4.shape',x.shape)\n",
    "        final_energy = x.sum(dim=(2,3)).unsqueeze_(2).unsqueeze_(3)\n",
    "        final_energy[final_energy==0] = 1\n",
    "        scale = initial_energy/final_energy\n",
    "        return x * scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SRnet(6,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('model parameters = ',sum(p.numel() for p in model.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the trainer and tester\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_helpers import trainMe, CreateCash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function:\n",
    "\n",
    "For this task, a MSELoss will be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "#def criterion(yhat, y):\n",
    "#    vec = (yhat - y).pow(2)\n",
    "#    print('yhat=',yhat.sum(),'y=',y.sum())\n",
    "#    return  torch.mean( vec ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=DataLoader(dataset=train_dataset,batch_size=516 ) #train_size\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.05)\n",
    "cacheSR = CreateCash(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from train_helpers import printProgressBar\n",
    "\n",
    "def trainMe2(train_loader, model, optimizer, criterion, epochs=1000, cache={'loss':[]}, device=torch.device(\"cpu\")):\n",
    "    print('len of cache is = ',len(cache['loss']))\n",
    "    isGPU = torch.cuda.is_available() and 'cuda'==device.type\n",
    "    if isGPU and not next(model.parameters()).is_cuda:\n",
    "        print('copy the model to GPU')\n",
    "        model.to(device)\n",
    "    tic = time.time()\n",
    "    for epoch in range(epochs):\n",
    "        for x, y in train_loader:\n",
    "            print('x.shape',x.shape)\n",
    "            print('y.shape',y.shape)\n",
    "            x = x.reshape((x.shape[0],6,64,64))\n",
    "            y = y.reshape((y.shape[0],6,64,64))\n",
    "            print('x.shape',x.shape)\n",
    "            print('y.shape',y.shape)\n",
    "            if isGPU:\n",
    "                if isinstance(x,type([])):\n",
    "                    x = [k.to(device) for k in x]\n",
    "                else: x = x.to(device)\n",
    "                y = y.to(device)\n",
    "            loss=criterion(model(x),y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        cache['loss'].append(loss.item())\n",
    "        printProgressBar(epoch, epochs, loss.item())\n",
    "    toc = time.time()\n",
    "    print('total time: %2.2f sec' %(toc-tic))\n",
    "    if isGPU:\n",
    "        print('cached',torch.cuda.memory_cached(device)/1e6,' MB')\n",
    "        torch.cuda.empty_cache() \n",
    "        print('Cache cleaned\\nRemaining cached memory',torch.cuda.memory_cached(device)/1e6,' MB')\n",
    "    return  cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# training the model\n",
    "cacheSR = trainMe2(train_loader, model, optimizer, criterion, 2, cacheSR, device)\n",
    "\n",
    "#saving the model\n",
    "torch.save({\n",
    "    'model_state_dict' : model.cpu().state_dict(),\n",
    "    'cache' : cacheSR,\n",
    "    },\n",
    "    'models/UNET_SR_dipion_dict_v1.pt')\n",
    "\n",
    "plt.plot(cacheSR['loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#on colab, download the generated sample\n",
    "files.download('models/UNET_SR_dipion_dict_v1.pt')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(cacheSR['loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continue training the model\n",
    "\n",
    "with different learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param_group in optimizer.param_groups:\n",
    "    param_group['lr'] = 0.025\n",
    "cacheSR = trainMe2(train_loader, model, optimizer, criterion, 120, cacheSR, device)\n",
    "plt.plot(cacheSR['loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ploting the results\n",
    "\n",
    "Now we will plot the obtained results of the SR images. The results will be later tested in the downstream task.\n",
    "\n",
    "In case we have newly trained model, we would like first to load the trained weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model\n",
    "checkpoint = torch.load('models/UNET_SR_dipion_dict_v1.pt')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "cacheSR = checkpoint['cache']\n",
    "model.train()\n",
    "print('model loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "DrawEventSR(train_dataset, event_number = 200, model = model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
