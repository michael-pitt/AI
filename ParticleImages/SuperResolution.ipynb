{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, urllib.request\n",
    "\n",
    "IS_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "    \n",
    "if IS_COLAB:\n",
    "    #create extra folders\n",
    "    !mkdir -pv data images model\n",
    "\n",
    "    # will install missing packages if running in colab\n",
    "    print('Installing uproot...')\n",
    "    !pip install uproot\n",
    "\n",
    "    #will download the data if running in colab\n",
    "    urllib.request.urlretrieve('https://cernbox.cern.ch/index.php/s/GRAyoFxBHAlMVpu/download',\n",
    "                               'data/events_6D64x64.root')\n",
    "    urllib.request.urlretrieve('https://cernbox.cern.ch/index.php/s/dZ9r1nvBRTpJMNW/download',\n",
    "                               'data/events_6D64x64_ATLAS_resolution_6D64x64.root')\n",
    "    print('ls data')\n",
    "    !ls data/*\n",
    "\n",
    "    #download additional modules used with the notebook\n",
    "    !wget https://raw.githubusercontent.com/mpitt82/AI/master/ParticleImages/train_helpers.py\n",
    "    !wget https://raw.githubusercontent.com/mpitt82/AI/master/ParticleImages/particleImages_helpers.py\n",
    "\n",
    "    print('Using COLAB: all additional packages are installed and the test data is downloaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Super resolution notebook\n",
    "\n",
    "In this notebook, the Super Resolution (SR) will be applied on detector images. The goal is to reconstruct detector images with higher resolution. In this notebook we will try several approaches to this task.\n",
    "\n",
    "The input data obtained using the [ATLAS-simplified](https://github.com/mpitt82/Geant4-models/tree/master/ATLAS-simplified) Geant4 simulation model. The bare data files are available [here](https://cernbox.cern.ch/index.php/s/oCg3en1GHAvYSTo?path=%2FCalo_RectangularGeo_diPion64x64%2Frun).\n",
    "\n",
    "Using the [Vector2Matrix.cc](https://github.com/mpitt82/Geant4-models/blob/master/ATLAS-simplified/scripts/Vector2Matrix.cc) script $6\\times 64\\times 64$ are obtaned, then with [Matrix2Matrix6L.cc](https://github.com/mpitt82/Geant4-models/blob/master/ATLAS-simplified/scripts/Matrix2Matrix6L.cc) script Low-resolution images are computed. For democtaric upsaling (used as a first approach) the [Matrix2Matrix6L.cc](https://github.com/mpitt82/Geant4-models/blob/master/ATLAS-simplified/scripts/Matrix6L2Matrix.cc) script can be used. **NOTE** All scripts executed in [CINT](https://root.cern.ch/cint). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standards imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data\n",
    "\n",
    "In this example, we will use two example files from cernbox folder, which have $\\sim$2k events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inputfileHR = 'data/events_6D64x64.root'\n",
    "inputfileLR = 'data/events_6D64x64_ATLAS_resolution_6D64x64.root'\n",
    "\n",
    "f = uproot.open(inputfileHR)\n",
    "treeHR = f['EventTree']\n",
    "\n",
    "f = uproot.open(inputfileLR)\n",
    "treeLR = f['EventTree']\n",
    "\n",
    "print('Total number of events in both files is = '+str(treeHR.numentries)+' (HR) and '+str(treeLR.numentries)+' (LR)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calorimeter images\n",
    "\n",
    "In this section, we will create calorimeter images from the cell hits using LR and HR input files. First we will constract a dataset using SRDataLoader defined in [train_helpers.py](train_helpers.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_helpers import SRDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SRDataLoader(treeLR, treeHR)\n",
    "test_dataset  = SRDataLoader(treeLR, treeHR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw a random image from the energy matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from particleImages_helpers import DrawEventSR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "DrawEventSR(train_dataset, event_number = 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n",
    "In the first implementation, we are using democratic interpulation, from varying resolution to a constant resolution of $6\\times 64 \\times 64$. The resulting image we will process through a model to recover the $HR$ image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_number = 0; #change this value to \"1\" if using the second GPU\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print('Availability of CUDA:',use_cuda)\n",
    "print('Availability of CUNN:',torch.backends.cudnn.enabled)\n",
    "print('Total number of GPU devices: ',torch.cuda.device_count())\n",
    "device = torch.device(\"cuda:\"+str(device_number) if torch.cuda.is_available() else \"cpu\")\n",
    "if use_cuda:\n",
    "    torch.cuda.set_device(device_number)\n",
    "    idevice = torch.cuda.current_device()\n",
    "    print('Will work on device number',idevice,', named: ',torch.cuda.get_device_name(idevice))\n",
    "else: print('will run on CPU, using',torch.get_num_threads(),'cores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class double_conv(nn.Module):\n",
    "    '''(conv => BN => ReLU) * 2'''\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(double_conv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1,bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1,bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class inconv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(inconv, self).__init__()\n",
    "        self.conv = double_conv(in_ch, out_ch)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class down(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(down, self).__init__()\n",
    "        self.mpconv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            double_conv(in_ch, out_ch)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.mpconv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class up(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, bilinear=True):\n",
    "        super(up, self).__init__()\n",
    "\n",
    "        #  would be a nice idea if the upsampling could be learned too,\n",
    "        #  but my machine do not have enough memory to handle all those weights\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_ch//2, in_ch//2, 2, stride=2)\n",
    "\n",
    "        self.conv = double_conv(in_ch, out_ch)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        \n",
    "        # input is CHW\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, (diffX // 2, diffX - diffX//2,\n",
    "                        diffY // 2, diffY - diffY//2))\n",
    "        \n",
    "        # for padding issues, see \n",
    "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
    "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
    "\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class outconv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(outconv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_ch, out_ch, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "    \n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes):\n",
    "        super(UNet, self).__init__()\n",
    "        self.inc = inconv(n_channels, 64)\n",
    "        #self.down1 = down(64, 128)\n",
    "        #self.down2 = down(128, 256)\n",
    "        #self.down3 = down(256, 512)\n",
    "        #self.down4 = down(512, 512)\n",
    "        #self.up1 = up(1024, 256)\n",
    "        #self.up2 = up(512, 128)\n",
    "        #self.up3 = up(256, 64)\n",
    "        #self.up4 = up(128, 64)\n",
    "        self.outc = outconv(64, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print('input.shape',x.shape)\n",
    "        x1 = self.inc(x)\n",
    "        #print('x1.shape',x1.shape)\n",
    "        #x2 = self.down1(x1)\n",
    "        #print('x2.shape',x2.shape)\n",
    "        #x3 = self.down2(x2)\n",
    "        #print('x3.shape',x3.shape)\n",
    "        #x4 = self.down3(x3)\n",
    "        #print('x4.shape',x4.shape)\n",
    "        #x5 = self.down4(x4)\n",
    "        #print('x5.shape',x5.shape)\n",
    "        #x = self.up1(x5, x4)\n",
    "        #print('(x5,x3).shape',x.shape)\n",
    "        #x = self.up2(x, x3)\n",
    "        #print('(x,x3).shape',x.shape)\n",
    "        #x = self.up3(x, x2)\n",
    "        #print('(x,x2).shape',x.shape)\n",
    "        #x = self.up4(x, x1)\n",
    "        #print('up4(x,x1).shape',x.shape)\n",
    "        #x = self.outc(x) replace by line bellow\n",
    "        x = self.outc(x1)\n",
    "        #print('x.shape',x.shape)\n",
    "        return F.relu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(6,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('model parameters = ',sum(p.numel() for p in model.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the trainer and tester\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_helpers import trainMe, CreateCash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criterion = nn.MSELoss()\n",
    "def criterion(yhat, y):\n",
    "    vec = (yhat - y).pow(2)\n",
    "#    print('yhat=',yhat.sum(),'y=',y.sum())\n",
    "    return  torch.mean( vec ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=DataLoader(dataset=train_dataset,batch_size=516 ) #train_size\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.01)\n",
    "cacheSR = CreateCash(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from train_helpers import printProgressBar\n",
    "\n",
    "def trainMe2(train_loader, model, optimizer, criterion, epochs=1000, cache={'loss':[]}, device=torch.device(\"cpu\")):\n",
    "    print('len of cache is = ',len(cache['loss']))\n",
    "    isGPU = torch.cuda.is_available() and 'cuda'==device.type\n",
    "    if isGPU and not next(model.parameters()).is_cuda:\n",
    "        print('copy the model to GPU')\n",
    "        model.to(device)\n",
    "    tic = time.time()\n",
    "    for epoch in range(epochs):\n",
    "        for x, y in train_loader:\n",
    "            #print('x.shape',x.shape)\n",
    "            #print('y.shape',y.shape)\n",
    "            x = x.reshape((x.shape[0],6,64,64))\n",
    "            y = y.reshape((y.shape[0],6,64,64))\n",
    "            #print('x.shape',x.shape)\n",
    "            #print('y.shape',y.shape)\n",
    "            if isGPU:\n",
    "                if isinstance(x,type([])):\n",
    "                    x = [k.to(device) for k in x]\n",
    "                else: x = x.to(device)\n",
    "                y = y.to(device)\n",
    "            loss=criterion(model(x),y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        cache['loss'].append(loss.item())\n",
    "        printProgressBar(epoch, epochs, loss.item())\n",
    "    toc = time.time()\n",
    "    print('total time: %2.2f sec' %(toc-tic))\n",
    "    if isGPU:\n",
    "        print('cached',torch.cuda.memory_cached(device)/1e6,' MB')\n",
    "        torch.cuda.empty_cache() \n",
    "        print('Cache cleaned\\nRemaining cached memory',torch.cuda.memory_cached(device)/1e6,' MB')\n",
    "    return  cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cacheSR = trainMe2(train_loader, model, optimizer, criterion, 10, cacheSR, device)\n",
    "#saving the model\n",
    "torch.save({\n",
    "    'model_state_dict' : model.cpu().state_dict(),\n",
    "    'cache' : cacheLR,\n",
    "    },\n",
    "    'models/UNET_SR_dipion_dict_v1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cacheSR['loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ploting the results\n",
    "\n",
    "Now we will plot the obtained results of the SR images. The results will be later tested in the downstream task.\n",
    "\n",
    "In case we have newly trained model, we would like first to load the trained weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model\n",
    "checkpoint = torch.load('models/UNET_SR_dipion_dict_v1.pt')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "cacheLR = checkpoint['cache']\n",
    "model.train()\n",
    "print('model loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DrawEventSR2(data_generator, event_number, model = None, device = torch.device(\"cpu\")):\n",
    "\n",
    "    imageLR, imageHR = data_generator[event_number]\n",
    "    \n",
    "    nimage = 2\n",
    "    Title = ['LR image', 'HR image',]\n",
    "    if model:\n",
    "        imageHRbar = model(torch.FloatTensor(imageLR).to(device)).cpu().detach().numpy()\n",
    "        nimage = 3\n",
    "        Title.append('SR image')\n",
    "    \n",
    "    fig, ax = plt.subplots(6, nimage, figsize=(10*nimage, 60))\n",
    "    LayerNames=['ECAL1','ECAL2','ECAL3','HCAL1','HCAL2','HCAL3']\n",
    "\n",
    "    for layer_i in range(6):\n",
    "\n",
    "        LR_image = imageLR[0][layer_i]\n",
    "        HR_image = imageHR[0][layer_i]\n",
    "\n",
    "        ax[layer_i][0].imshow( LR_image, cmap='plasma', vmin=0.001, vmax=10.8 )\n",
    "        ax[layer_i][1].imshow( HR_image, cmap='plasma', vmin=0.001, vmax=10.8 )\n",
    "\n",
    "        major_ticks = np.arange(-0.5, 63.5, 1)\n",
    "        minor_ticks = np.arange(-0.5, 63.5, 1)\n",
    "\n",
    "        ax[layer_i][0].set_ylabel(LayerNames[layer_i],fontsize=64)\n",
    "        for ipad in range(nimage) : \n",
    "            ax[layer_i][ipad].set_xticks(minor_ticks, minor=True)\n",
    "            ax[layer_i][ipad].set_yticks(minor_ticks, minor=True)\n",
    "            ax[layer_i][ipad].grid(which='minor')\n",
    "            ax[0][ipad].set_title(Title[ipad]+' ' , fontsize=48)     \n",
    "        ax[layer_i][0].text(5,5,'E = %2.2f GeV'%(LR_image.sum()/1e3),fontsize=32,bbox={'facecolor': 'white'})\n",
    "        ax[layer_i][1].text(5,5,'E = %2.2f GeV'%(HR_image.sum()/1e3),fontsize=32,bbox={'facecolor': 'white'})\n",
    "        \n",
    "        if model:\n",
    "            SR_image = imageHRbar[0][layer_i]\n",
    "            ax[layer_i][2].imshow( SR_image, cmap='plasma', vmin=0.001, vmax=10.8 )\n",
    "            ax[layer_i][2].text(5,5,'E = %2.2f GeV'%(SR_image.sum()/1e3),fontsize=32,bbox={'facecolor': 'white'})\n",
    "\n",
    "    plt.tight_layout()\n",
    "    fig.savefig('images/SR_ev_' + str(event_number) + '.pdf')\n",
    "    fig.savefig('images/SR_ev_' + str(event_number) + '.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DrawEventSR2(train_dataset, event_number = 200, model = model, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
