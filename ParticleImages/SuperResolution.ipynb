{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "IS_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "#create extra folders\n",
    "if IS_COLAB:\n",
    "    !mkdir -pv data images\n",
    "\n",
    "# will install missing packages if running in colab\n",
    "if IS_COLAB:\n",
    "  print('Installing uproot...')\n",
    "  !pip install uproot\n",
    "\n",
    "#will download the data if running in colab\n",
    "if IS_COLAB:\n",
    "    urllib.request.urlretrieve('https://cernbox.cern.ch/index.php/s/GRAyoFxBHAlMVpu/download', 'data/events_6D64x64.root')\n",
    "    urllib.request.urlretrieve('https://cernbox.cern.ch/index.php/s/dZ9r1nvBRTpJMNW/download', 'data/events_6D64x64_ATLAS_resolution_6D64x64.root')\n",
    "    print('ls data')\n",
    "    !ls data/*\n",
    "\n",
    "#download additional modules used with the notebook\n",
    "if IS_COLAB:\n",
    "    !wget https://raw.githubusercontent.com/mpitt82/AI/master/ParticleImages/train_helpers.py\n",
    "    !wget https://raw.githubusercontent.com/mpitt82/AI/master/ParticleImages/particleImages_helpers.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Super resolution notebook\n",
    "\n",
    "In this notebook, the Super Resolution (SR) will be applied on detector images. The goal is to reconstruct detector images with higher resolution. In this notebook we will try several approaches to this task.\n",
    "\n",
    "The input data obtained using the [ATLAS-simplified](https://github.com/mpitt82/Geant4-models/tree/master/ATLAS-simplified) Geant4 simulation model. The bare data files are available [here](https://cernbox.cern.ch/index.php/s/oCg3en1GHAvYSTo?path=%2FCalo_RectangularGeo_diPion64x64%2Frun).\n",
    "\n",
    "Using the [Vector2Matrix.cc](https://github.com/mpitt82/Geant4-models/blob/master/ATLAS-simplified/scripts/Vector2Matrix.cc) script $6\\times 64\\times 64$ are obtaned, then with [Matrix2Matrix6L.cc](https://github.com/mpitt82/Geant4-models/blob/master/ATLAS-simplified/scripts/Matrix2Matrix6L.cc) script Low-resolution images are computed. For democtaric upsaling (used as a first approach) the [Matrix2Matrix6L.cc](https://github.com/mpitt82/Geant4-models/blob/master/ATLAS-simplified/scripts/Matrix6L2Matrix.cc) script can be used. **NOTE** All scripts executed in [CINT](https://root.cern.ch/cint). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standards imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data\n",
    "\n",
    "In this example, we will use two example files from cernbox folder, which have $\\sim$2k events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of events in both files is = 2100 (HR) and 2100 (LR)\n"
     ]
    }
   ],
   "source": [
    "inputfileHR = 'data/events_6D64x64.root'\n",
    "inputfileLR = 'data/events_6D64x64_ATLAS_resolution_6D64x64.root'\n",
    "\n",
    "f = uproot.open(inputfileHR)\n",
    "treeHR = f['EventTree']\n",
    "\n",
    "f = uproot.open(inputfileLR)\n",
    "treeLR = f['EventTree']\n",
    "\n",
    "print('Total number of events in both files is = '+str(treeHR.numentries)+' (HR) and '+str(treeLR.numentries)+' (LR)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calorimeter images\n",
    "\n",
    "In this section, we will create calorimeter images from the cell hits using LR and HR input files. First we will constract a dataset using SRDataLoader defined in [train_helpers.py](train_helpers.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/mpitt82/AI/master/ParticleImages/train_helpers.py\n",
    "!wget https://raw.githubusercontent.com/mpitt82/AI/master/ParticleImages/particleImages_helpers.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_helpers import SRDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SRDataLoader(treeLR, treeHR)\n",
    "test_dataset  = SRDataLoader(treeLR, treeHR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw a random image from the energy matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from particleImages_helpers import DrawEventSR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "DrawEventSR(train_dataset, event_number = 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n",
    "In the first implementation, we are using democratic interpulation, from varying resolution to a constant resolution of $6\\times 64 \\times 64$. The resulting image we will process through a model to recover the $HR$ image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Availability of CUDA: False\n",
      "Availability of CUNN: True\n",
      "Total number of GPU devices:  0\n",
      "will run on CPU, using 8 cores\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device_number = 1; #change this value to \"1\" if using the second GPU\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print('Availability of CUDA:',use_cuda)\n",
    "print('Availability of CUNN:',torch.backends.cudnn.enabled)\n",
    "print('Total number of GPU devices: ',torch.cuda.device_count())\n",
    "device = torch.device(\"cuda:\"+str(device_number) if torch.cuda.is_available() else \"cpu\")\n",
    "if use_cuda:\n",
    "    torch.cuda.set_device(device_number)\n",
    "    idevice = torch.cuda.current_device()\n",
    "    print('Will work on device number',idevice,', named: ',torch.cuda.get_device_name(idevice))\n",
    "else: print('will run on CPU, using',torch.get_num_threads(),'cores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class double_conv(nn.Module):\n",
    "    '''(conv => BN => ReLU) * 2'''\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(double_conv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1,bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1,bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class inconv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(inconv, self).__init__()\n",
    "        self.conv = double_conv(in_ch, out_ch)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class down(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(down, self).__init__()\n",
    "        self.mpconv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            double_conv(in_ch, out_ch)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.mpconv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class up(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, bilinear=True):\n",
    "        super(up, self).__init__()\n",
    "\n",
    "        #  would be a nice idea if the upsampling could be learned too,\n",
    "        #  but my machine do not have enough memory to handle all those weights\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_ch//2, in_ch//2, 2, stride=2)\n",
    "\n",
    "        self.conv = double_conv(in_ch, out_ch)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        \n",
    "        # input is CHW\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, (diffX // 2, diffX - diffX//2,\n",
    "                        diffY // 2, diffY - diffY//2))\n",
    "        \n",
    "        # for padding issues, see \n",
    "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
    "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
    "\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class outconv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(outconv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_ch, out_ch, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "    \n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes):\n",
    "        super(UNet, self).__init__()\n",
    "        self.inc = inconv(n_channels, 64)\n",
    "        #self.down1 = down(64, 128)\n",
    "        #self.down2 = down(128, 256)\n",
    "        #self.down3 = down(256, 512)\n",
    "        #self.down4 = down(512, 512)\n",
    "        #self.up1 = up(1024, 256)\n",
    "        #self.up2 = up(512, 128)\n",
    "        #self.up3 = up(256, 64)\n",
    "        #self.up4 = up(128, 64)\n",
    "        self.outc = outconv(64, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        print('input.shape',x.shape)\n",
    "        x1 = self.inc(x)\n",
    "        print('x1.shape',x1.shape)\n",
    "        #x2 = self.down1(x1)\n",
    "        #print('x2.shape',x2.shape)\n",
    "        #x3 = self.down2(x2)\n",
    "        #print('x3.shape',x3.shape)\n",
    "        #x4 = self.down3(x3)\n",
    "        #print('x4.shape',x4.shape)\n",
    "        #x5 = self.down4(x4)\n",
    "        #print('x5.shape',x5.shape)\n",
    "        #x = self.up1(x5, x4)\n",
    "        #print('(x5,x3).shape',x.shape)\n",
    "        #x = self.up2(x, x3)\n",
    "        #print('(x,x3).shape',x.shape)\n",
    "        #x = self.up3(x, x2)\n",
    "        #print('(x,x2).shape',x.shape)\n",
    "        #x = self.up4(x, x1)\n",
    "        #print('up4(x,x1).shape',x.shape)\n",
    "        #x = self.outc(x) replace by line bellow\n",
    "        x = self.outc(x1)\n",
    "        print('x.shape',x.shape)\n",
    "        return F.relu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(6,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model parameters =  40966\n"
     ]
    }
   ],
   "source": [
    "print('model parameters = ',sum(p.numel() for p in model.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the trainer and tester\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_helpers import trainMe, CreateCash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criterion = nn.MSELoss()\n",
    "def criterion(yhat, y):\n",
    "    vec = (yhat - y).pow(2)\n",
    "#    print('yhat=',yhat.sum(),'y=',y.sum())\n",
    "    return  torch.mean( vec ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=DataLoader(dataset=train_dataset,batch_size=21000 ) #train_size\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.01)\n",
    "cacheSR = CreateCash(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def trainMe2(train_loader, model, optimizer, criterion, epochs=1000, cache={'loss':[]}, device=torch.device(\"cpu\")):\n",
    "    print('len of cache is = ',len(cache['loss']))\n",
    "    isGPU = torch.cuda.is_available() and 'cuda'==device.type\n",
    "    if isGPU and not next(model.parameters()).is_cuda:\n",
    "        print('copy the model to GPU')\n",
    "        model.to(device)\n",
    "    tic = time.time()\n",
    "    for epoch in range(epochs):\n",
    "        for x, y in train_loader:\n",
    "            #print('x.shape',x.shape)\n",
    "            #print('y.shape',y.shape)\n",
    "            x = x.reshape((128,6,64,64))\n",
    "            y = y.reshape((128,6,64,64))\n",
    "            #print('x.shape',x.shape)\n",
    "            #print('y.shape',y.shape)\n",
    "            if isGPU:\n",
    "                if isinstance(x,type([])):\n",
    "                    x = [k.to(device) for k in x]\n",
    "                else: x = x.to(device)\n",
    "                y = y.to(device)\n",
    "            loss=criterion(model(x),y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        cache['loss'].append(loss.item())\n",
    "        printProgressBar(epoch, epochs, loss.item())\n",
    "    toc = time.time()\n",
    "    print('total time: %2.2f sec' %(toc-tic))\n",
    "    if isGPU:\n",
    "        print('cached',torch.cuda.memory_cached(device)/1e6,' MB')\n",
    "        torch.cuda.empty_cache() \n",
    "        print('Cache cleaned\\nRemaining cached memory',torch.cuda.memory_cached(device)/1e6,' MB')\n",
    "    return  cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of cache is =  0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[128, 6, 64, 64]' is invalid for input of size 51609600",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-ce2ba28acda9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcacheSR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainMe2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcacheSR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-18-901ef26af789>\u001b[0m in \u001b[0;36mtrainMe2\u001b[1;34m(train_loader, model, optimizer, criterion, epochs, cache, device)\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[1;31m#print('x.shape',x.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[1;31m#print('y.shape',y.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[1;31m#print('x.shape',x.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: shape '[128, 6, 64, 64]' is invalid for input of size 51609600"
     ]
    }
   ],
   "source": [
    "cacheSR = trainMe2(train_loader, model, optimizer, criterion, 10, cacheSR, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
